{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b086d5b2",
   "metadata": {},
   "source": [
    "#### Download/Install the Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87bba00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install -q --upgrade pip\n",
    "!{sys.executable} -m pip install -q numpy pandas sklearn\n",
    "!{sys.executable} -m pip install -q nltk spacy gensim wordcloud textblob contractions clean-text unidecode "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a465ce3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.10.9\n"
     ]
    }
   ],
   "source": [
    "from platform import python_version\n",
    "print(python_version())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e878c8",
   "metadata": {},
   "source": [
    "# From Bayes' Theorum to Naive Bayes' Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef1b118",
   "metadata": {},
   "source": [
    "## Marginal Probability\n",
    "- ***Probability*** defines the ***`likelihood of occurance of an event`*** \n",
    "- Defined as the ratio of the number of favourite outcomes to the total number of outcomes of an event\n",
    ">-      P(Event) = (Number of favourite outcomes)/(Total outcomes)\n",
    "- Marginal Probability is the probability of an event irrespective of all the other events\n",
    "- The value of the probability of an event to happen can lie between 0 to 1 because the favourable number of outcomes can never cross the total number of outcomes\n",
    "- When the probability of something approaches 1, then it means it is very likely, and when the probablity approaches to 0, then it means that it is very unlikely\n",
    "- ***Independent Events***: Two events are said to independent, if the probability of occuring of one event has no impact on the probability of occuring of another event\n",
    "- In order to compute the probability of two independent events, we use ***`Join Probability` (Common Area)***\n",
    ">- P(A and B) = P(A) * P(B)\n",
    "- ***Independent Events***: Two events are said to dependent happing one after another, if the probability of occuring of one event has impact on the probability of occuring of another event \n",
    ">- Dependent events and Conditional Probability\n",
    ">- P(A|B) = P(A and B)/P(B)\n",
    ">- P(B|A) = P(A and B)/P(A)\n",
    "- In case of two independent events, \n",
    ">- P(A|B) = P(A and B)/P(B) = P(A) * P(B)/P(B) = P(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ed422f",
   "metadata": {},
   "source": [
    "## From Conditional Probability to Bayes' Theorum\n",
    "- It is a way of calculating conditional probability without the joint probability\n",
    ">- P(A|B) = (P(A) * P(B|A))/P(B)\n",
    "- P(A|B) is ***`Posterior Probability/Conditional Probability`***: Probability of an event that is calculated after all the information related to the event has been accounted for\n",
    "- P(A) is ***`Prior Probability`***: Probability of an event that is calculated before considering the new information obtained\n",
    "- P(B|A) is ***`Likelihood`***: Reverse of Posterior Probability\n",
    "- P(B) is known as ***`Normalization Constant`***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a8da51",
   "metadata": {},
   "source": [
    "# Naive Bayes' Classifier\n",
    "- It is a probabilistic ML algorithm that uses Bayes' Theorum for supervised ML classifications. \n",
    "- This algorithm makes an assumptions that all the input features are ***`independent`*** to each other and make ***`Equal`*** contributions \n",
    "- These are the three types of Naive Bayes' Theorum under the Scikit-Learn Library\n",
    "     1) ***Bernoulli Naive Bayes' (`BernoulliNB`)***: It is used when all the input features are binary such that they take only two values. Means 0's can represent \"Word does not occur in the document\" and 1's represent \"Word occurs in the documents\"\n",
    "     2) ***Multinomial Naive Bayes' (`MultinomialNB`)***: It is used when all the input features are discrete having integer values. For example: frequency of occurrences of a term/word in the document. It is suitable for the classifications with discrete features (word counts for text classification). However, in practice, fractional counts such as tf-idf may also work\n",
    "     3) ***Gaussian Naiva Bayes' (`GaussianNB`)***: It is used when the input features are continuous values (age, distance, inflation etc), whose probabilities can be modeled using a Gaussian/Normal Distribution. \n",
    "- The output labels can be\n",
    "     1) ***Binary***: Assign observation to one of two groups (spam/ham, yes/no, healthy/sick, etc)\n",
    "     2) ***Multinomial***: Assign observation to one to N-groups (happy, sad, fear, surprise, joy) \n",
    "     3) ***Ordinal***: Assign one of N-ordered groups (baby, child, adult, young, elder, old)\n",
    "     4) ***Multiclass***: Assign obserrvation to K of N groups. Assign more than one label to an observation. (happy, baby), (sad, child), (angry, adult)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836fd045",
   "metadata": {},
   "source": [
    ">-   P(y/ x1, x2, x3) = P(y) * P(x1/y) * P(x2/y) * P(x3/y) / P(x1) * P(x2) * P(x3)\n",
    "- ***As denominator value remains same for all the labels, so we can remove it after replacing proportional sign with equal sign***\n",
    "- After that equal will become\n",
    ">-   P(y/ x1, x2, x3) ***`proportional to`*** argmax(P(y) * P(x1/y) * P(x2/y) * P(x3/y)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c32b75b",
   "metadata": {},
   "source": [
    "#### Example # 01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f96201",
   "metadata": {},
   "source": [
    ">-    P(y=yes | x1 = cloudy, x2 = cool, x3 = normal)  ***=***  P(y = yes) * P(y|x1) * P(y|x2) * P(y|x3)\n",
    ">-    P(y=no | x1 = cloudy, x2 = cool, x3 = normal)  ***=***  P(y = no) * P(y|x1) * P(y|x2) * P(y|x3)\n",
    "- ***IF probability value of yes is greater than no than it will rain on this day***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157a0398",
   "metadata": {},
   "source": [
    "***Calculate the word count, conditional probabilities, and perform Laplace Smoothing***\n",
    ">- frequency of a word in the document = freq(w,class)\n",
    ">- Conditional Probability = P(w1 | class) = freq(w1,class)/N(total number of word in the class-->\n",
    "+ve/-ve class)\n",
    "- ***There may a word in the document with frequency in any class, to address this issue we use, laplace smoothing***\n",
    ">- P(w1 | class) = (freq(w1,class) + 1)/(\n",
    "N(total number of word class) + V(number of unique words in the vocabulary)\n",
    "- ***Power Words: Words in the document that define the class of the document***\n",
    "- ***Opposite words from power words are those words that have almost same probabilities in both the class, so they don't effect the model***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4dcd987",
   "metadata": {},
   "source": [
    "#### Load Downloaded dataset (`SMSSpanCollection`) in Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c591fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8b3a1153",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                               text\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('datasets/SMSSpamCollection', sep = '\\t', header = None, names = ['label','text'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b482ef7",
   "metadata": {},
   "source": [
    "## Text Preprocessing\n",
    "#### a) Basic Preprocessing, Tokenization, Stopward Removal, and Stemming "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c46aa8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import contractions\n",
    "from cleantext import clean\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "ps = PorterStemmer()\n",
    "wn = WordNetLemmatizer()\n",
    "\n",
    "def text_preprocessing(mystr):\n",
    "    mystr = mystr.lower()                                                # Case Folding\n",
    "    mystr = re.sub('\\w*\\d\\w*', '', mystr)                                # Remove digits\n",
    "    mystr = re.sub('\\n', ' ', mystr)                                      # Remove new line characters with space\n",
    "    mystr = re.sub('[''\"\"....]', '', mystr)                              # Remove double quotes and single quotes\n",
    "    mystr = re.sub('<.*?>', '', mystr)                                   # Remove HTML tags\n",
    "    mystr = re.sub(r'\\[.*?\\]', '', mystr)                                # Remove text in the square brackets\n",
    "    mystr = re.sub('https?://\\S+|www.\\.\\S+','', mystr)                   # Remove URLs\n",
    "    mystr = re.sub('\\n', ' ', mystr)  \n",
    "    mystr = clean(mystr, no_emoji=True)                                  # Remove emojis\n",
    "    mystr = ''.join([i for i in mystr if i not in string.punctuation])   # Remove punctuations\n",
    "    mystr = ' '.join([contractions.fix(i) for i in mystr.split()])        # Expand Contractions\n",
    "    tokens = word_tokenize(mystr)                                        # Tokenize the string\n",
    "    mystr = ''.join([i for i in mystr if i not in string.punctuation])\n",
    "    tokens = [i for i in tokens if i not in stop_words]                  # Remove stop words\n",
    "#     tokens = [ps.stem(i) for i in tokens]                              # Stemming\n",
    "    tokens = [wn.lemmatize(i) for i in tokens]                           # Lemmatization\n",
    "    new_str = ' '.join(tokens)\n",
    "    return new_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0952c094",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4bf53a33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                               text\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2761e01a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'dtype'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'dtype'"
     ]
    }
   ],
   "source": [
    "df['text'][4].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7526fd1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ptext'] = df['text'].apply(lambda x: text_preprocessing(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "917e5d69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>7597</th>\n",
       "      <th>7598</th>\n",
       "      <th>7599</th>\n",
       "      <th>7600</th>\n",
       "      <th>7601</th>\n",
       "      <th>7602</th>\n",
       "      <th>7603</th>\n",
       "      <th>7604</th>\n",
       "      <th>7605</th>\n",
       "      <th>7606</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7607 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0     1     2     3     4     5     6     7     8     9     ...  7597  \\\n",
       "0     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "1     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "2     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "3     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "4     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "\n",
       "   7598  7599  7600  7601  7602  7603  7604  7605  7606  \n",
       "0     0     0     0     0     0     0     0     0     0  \n",
       "1     0     0     0     0     0     0     0     0     0  \n",
       "2     0     0     0     0     0     0     0     0     0  \n",
       "3     0     0     0     0     0     0     0     0     0  \n",
       "4     0     0     0     0     0     0     0     0     0  \n",
       "\n",
       "[5 rows x 7607 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169a1ed5",
   "metadata": {},
   "source": [
    "#### Verification of Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d89321cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Is that seriously how you spell his name?'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'][20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0948e5ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'seriously spell name'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['ptext'][20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a869b87",
   "metadata": {},
   "source": [
    "#### Text Vectorization Using Bag of Words (BoW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3253081",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer()\n",
    "bow = cv.fit_transform(df['ptext'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "926c37d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7607\n"
     ]
    }
   ],
   "source": [
    "print(len(cv.vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "18841fd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['8ud' 'aa' 'aah' ... 'zoom' 'zouk' 'zyada']\n"
     ]
    }
   ],
   "source": [
    "print(cv.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5f936567",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 7607)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "19703362",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<5572x7607 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 42346 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37f42be",
   "metadata": {},
   "source": [
    ">- The DTM contains 5572 rows as there are 5572 messages\n",
    ">- The DTM contains 7607 columns as there are 7606 unique words in the vocabulary of messages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ac9cb858",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Since bow is a sparse matrix, so change it to dense matrix or array, we can use the numpt toarray() method\n",
    "#bow.toarray()\n",
    "bow.todense()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b304593",
   "metadata": {},
   "source": [
    "### Understand the Sparsity of the Resulting Document-Term-Matrix (DTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "96b6d472",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42386204"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_cells = bow.shape[0] * bow.shape[1]\n",
    "total_cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0f62ca67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42346"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nonzero_cells = bow.nnz\n",
    "nonzero_cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4e8fed3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09990514838271435"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percentage = (nonzero_cells/total_cells)*100\n",
    "percentage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91faa410",
   "metadata": {},
   "source": [
    ">- 99.9% cells contains a zero values\n",
    ">- In order to save memory space and speed up algebric operations, we use sparse representation of matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196e6b5a",
   "metadata": {},
   "source": [
    "### Check out and Understand BoW vector representation of a specific sms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "247bacbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Had your mobile 11 months or more? U R entitled to Update to the latest colour mobiles with camera for Free! Call The Mobile Update Co FREE on 08002986030\n",
      "\n",
      " mobile month r entitled update latest colour mobile camera free call mobile update co free\n",
      "\n",
      " spam\n"
     ]
    }
   ],
   "source": [
    "print(df.text[9])\n",
    "print('\\n', df['ptext'][9])\n",
    "print('\\n', df['label'][9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f4fb23cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow[9].nnz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4053aeb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 2396)\t2\n",
      "  (0, 914)\t1\n",
      "  (0, 4116)\t3\n",
      "  (0, 4147)\t1\n",
      "  (0, 2007)\t1\n",
      "  (0, 6957)\t2\n",
      "  (0, 3583)\t1\n",
      "  (0, 1229)\t1\n",
      "  (0, 936)\t1\n",
      "  (0, 1197)\t1\n"
     ]
    }
   ],
   "source": [
    "print(bow[9])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30169eab",
   "metadata": {},
   "source": [
    "### View the Document Term Matrix in Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6bb1cfab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>7597</th>\n",
       "      <th>7598</th>\n",
       "      <th>7599</th>\n",
       "      <th>7600</th>\n",
       "      <th>7601</th>\n",
       "      <th>7602</th>\n",
       "      <th>7603</th>\n",
       "      <th>7604</th>\n",
       "      <th>7605</th>\n",
       "      <th>7606</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 7607 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     1     2     3     4     5     6     7     8     9     ...  7597  \\\n",
       "0        0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "1        0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "2        0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "3        0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "4        0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "...    ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   ...   \n",
       "5567     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "5568     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "5569     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "5570     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "5571     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "\n",
       "      7598  7599  7600  7601  7602  7603  7604  7605  7606  \n",
       "0        0     0     0     0     0     0     0     0     0  \n",
       "1        0     0     0     0     0     0     0     0     0  \n",
       "2        0     0     0     0     0     0     0     0     0  \n",
       "3        0     0     0     0     0     0     0     0     0  \n",
       "4        0     0     0     0     0     0     0     0     0  \n",
       "...    ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
       "5567     0     0     0     0     0     0     0     0     0  \n",
       "5568     0     0     0     0     0     0     0     0     0  \n",
       "5569     0     0     0     0     0     0     0     0     0  \n",
       "5570     0     0     0     0     0     0     0     0     0  \n",
       "5571     0     0     0     0     0     0     0     0     0  \n",
       "\n",
       "[5572 rows x 7607 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(data = bow.todense())\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f5353f",
   "metadata": {},
   "source": [
    "## Model Building (Feed Training Data to ML Model)\n",
    "#### Choose ML Model\n",
    "- We can use one of the following ML Model\n",
    ">- 1) Naive Bayes\n",
    ">- 2) Logistic Regression\n",
    ">- 3) Support Vector Machine\n",
    ">- 4) K-Nearest Neighbours\n",
    ">- 5) Decision Tree Classifier\n",
    ">- 6) Random Forest Classifier\n",
    ">- 7) XGBoost Classifier\n",
    ">- 8) AdaBoost Classifier\n",
    "\n",
    "### Naive Bayes' Classifier\n",
    "- It is a probabilistic ML algorithm that uses Bayes' Theorum for supervised ML classifications. \n",
    "- This algorithm makes an assumptions that all the input features are ***`independent`*** to each other and make ***`Equal`*** contributions \n",
    "- These are the three types of Naive Bayes' Theorum under the Scikit-Learn Library\n",
    "     1) ***Bernoulli Naive Bayes' (`BernoulliNB`)***: It is used when all the input features are binary such that they take only two values. Means 0's can represent \"Word does not occur in the document\" and 1's represent \"Word occurs in the documents\"\n",
    "     2) ***Multinomial Naive Bayes' (`MultinomialNB`)***: It is used when all the input features are discrete having integer values. For example: frequency of occurrences of a term/word in the document. It is suitable for the classifications with discrete features (word counts for text classification). However, in practice, fractional counts such as tf-idf may also work\n",
    "     3) ***Gaussian Naiva Bayes' (`GaussianNB`)***: It is used when the input features are continuous values (age, distance, inflation etc), whose probabilities can be modeled using a Gaussian/Normal Distribution. \n",
    "- The output labels can be\n",
    "     1) ***Binary***: Assign observation to one of two groups (spam/ham, yes/no, healthy/sick, etc)\n",
    "     2) ***Multinomial***: Assign observation to one to N-groups (happy, sad, fear, surprise, joy) \n",
    "     3) ***Ordinal***: Assign one of N-ordered groups (baby, child, adult, young, elder, old)\n",
    "     4) ***Multiclass***: Assign obserrvation to K of N groups. Assign more than one label to an observation. (happy, baby), (sad, child), (angry, adult)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13fd167f",
   "metadata": {},
   "source": [
    "## Split Data for Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f113aff0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<5572x7607 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 42346 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = bow\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "05ed3ba5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        ham\n",
       "1        ham\n",
       "2       spam\n",
       "3        ham\n",
       "4        ham\n",
       "        ... \n",
       "5567    spam\n",
       "5568     ham\n",
       "5569     ham\n",
       "5570     ham\n",
       "5571     ham\n",
       "Name: label, Length: 5572, dtype: object"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Since our output label can belong to two classes ham or spam so we need to vectorize to that columns to zero and one\n",
    "# This can be done using one-hot encoding\n",
    "y = df['label']\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "34c6cdd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 5, shuffle = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "329fa921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the Training Input Data: (3900, 7607)\n",
      "\n",
      " Size of the Test Input Data:  (1672, 7607)\n",
      "Size of the Training Label Data: (3900,)\n",
      "\n",
      " Size of the Test label Data:  (1672,)\n"
     ]
    }
   ],
   "source": [
    "print('Size of the Training Input Data:', X_train.shape)\n",
    "print('\\n Size of the Test Input Data: ', X_test.shape)\n",
    "print('Size of the Training Label Data:', y_train.shape)\n",
    "print('\\n Size of the Test label Data: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297da485",
   "metadata": {},
   "source": [
    "## Fit Naive-Bayes' Classifier Model on Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3574a001",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "model = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ad567452",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244037e6",
   "metadata": {},
   "source": [
    ">- A ML model training model training actually creates a mathematical representation relationship between the input features and output labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1a3348",
   "metadata": {},
   "source": [
    "## Evaluate Metrics for Classification ML Model \n",
    "### 1) Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ed6ba685",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['spam', 'ham', 'spam', ..., 'ham', 'ham', 'ham'], dtype='<U4')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(X_test)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b7d07237",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2095    spam\n",
       "5343     ham\n",
       "564     spam\n",
       "3849     ham\n",
       "3317     ham\n",
       "        ... \n",
       "4569     ham\n",
       "3714     ham\n",
       "1885     ham\n",
       "5313     ham\n",
       "1922     ham\n",
       "Name: label, Length: 1672, dtype: object"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9f6c3e56",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1410,   39],\n",
       "       [  13,  210]], dtype=int64)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "cm\n",
    "# Since there are two classes ham and spam in the label, so 2*2 matrix, if n-classes then n*n matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a8410fb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x124624759f0>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "cmd = ConfusionMatrixDisplay(confusion_matrix = cm, display_labels = model.classes_)\n",
    "cmd.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d416f45a",
   "metadata": {},
   "source": [
    "### 2) Accuracy\n",
    "- Accuracy actually answers the question: ***How often is the model correct***\n",
    ">- Accuracy = (Count of Correct Answers of the Classifier)/(Count of all the Questions asked from Classifier)\n",
    ">- Accuracy = (TN + TP)/(TN + TP + FP + FN)\n",
    ">- Accuracy = (1410 + 210)/(1410 + 210 + 13 + 39)\n",
    ">- Accuracy is an evaluation metric used for classification algorithms that tells us what fraction of time the classifier are correct in the classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bf8612f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9688995215311005\n",
      "1620\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test, predictions))\n",
    "print(accuracy_score(y_test, predictions, normalize = False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9254ce",
   "metadata": {},
   "source": [
    "### 3) The Accuracy Paradox\n",
    "- Accuracy does not prove to be a good evaluation metric in case of imbalance data sets; which are very common in the real word scenarios\n",
    "- So, a classifier that always predicts the majority class, in highly imbalanced dataset, will always have a high accurcay score\n",
    "- Therefore, accuracy is not a good evaluation metrics, when the goal is to discover the rare events\n",
    "- ***Conclusion***: We should not rely solely on Accuracy as a metric. This is where precision, recall and F1 score comes in"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ca5738",
   "metadata": {},
   "source": [
    "### 4) Precision\n",
    "- Precision actually answers the question: ***When prediction is positive, how often it matches with the ground positives***\n",
    ">-   Precision = True Positives/Predicted Positives = TP / (TP + FP)\n",
    "- If we consider `ham` label as positive,\n",
    ">-   Precision = 1410 /(1410 + 13) = 0.9908\n",
    "- If we consider `span` label as positive\n",
    ">-   Precision = 210 / (210 + 39) = 0.8433"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2da86ad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9908643710470836\n",
      "0.8433734939759037\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "print(precision_score(y_test, predictions, pos_label = 'ham'))\n",
    "print(precision_score(y_test, predictions, pos_label = 'spam'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4984fb5c",
   "metadata": {},
   "source": [
    "### 5) Recall (Sensitivity)\n",
    "- Recall actually answers the question: ***When ground reality is positive, how often it is correct***\n",
    ">-   Recall = True Positives/Real Positives = TP / (TP + FN)\n",
    "- If we consider `ham` label as positive,\n",
    ">-   Precision = 1410 /(1410 + 39) = 0.9730\n",
    "- If we consider `span` label as positive\n",
    ">-   Precision = 210 / (210 + 13) = 0.9417\n",
    "- If recall is high, that means the classifier is good in identifying real patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f599f4b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9417040358744395\n",
      "0.9730848861283644\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "print(recall_score(y_test, predictions, pos_label = 'spam'))\n",
    "print(recall_score(y_test, predictions, pos_label = 'ham'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7dde0f1",
   "metadata": {},
   "source": [
    "### 6) F-1 Score\n",
    "- Precision and accuracy alone do not solve the Accuracy Paradox. So, we combine both these metrics to create a new metric called F-1 Score, which is the harmonic mean of the precision and recall\n",
    "- We use harmonic mean instead of arithmetic mean because harmonic mean punishes the outliers more. In other words, the harmonic means goes to zero if either of recall and precision ends up being zero\n",
    ">- F1_score = (inv(inv(P) + inv(R)))/2\n",
    ">- F1_Score = (2PR/(P+R))\n",
    "- F1_Score will be high if both precision and recall are high\n",
    "- F1_Score will be low if either of precision and recall is low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4ad31eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.99      0.97      0.98      1449\n",
      "        spam       0.84      0.94      0.89       223\n",
      "\n",
      "    accuracy                           0.97      1672\n",
      "   macro avg       0.92      0.96      0.94      1672\n",
      "weighted avg       0.97      0.97      0.97      1672\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
